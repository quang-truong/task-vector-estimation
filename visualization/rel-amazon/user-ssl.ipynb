{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "rootutils.setup_root('.', indicator='.project-root', pythonpath=True)\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from relbench.base import Table\n",
    "from IPython.display import display\n",
    "import duckdb\n",
    "\n",
    "from src.helpers.task_vector_generation_helper import get_task_columns_dict, generate_task_vector_clauses, get_timestamps_for_split, transform_features\n",
    "from src.helpers.relbench_helper import get_dataset\n",
    "from src.helpers.dataset_helper import get_default_db\n",
    "from src.helpers.database_helper import read_stypes_cache\n",
    "from src.definitions import DATA_DIR\n",
    "\n",
    "dataset_name = 'rel-amazon'\n",
    "stype_dict = read_stypes_cache(os.path.join(DATA_DIR, dataset_name, 'stypes.json'))\n",
    "dataset = get_dataset(dataset_name)\n",
    "timedelta = pd.Timedelta(days=365 // 4)\n",
    "num_eval_timestamps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, _, _ = get_default_db(dataset_name, dataset, 'glove')\n",
    "task_columns_dict = get_task_columns_dict(db, stype_dict)\n",
    "\n",
    "sub_customer_review_clauses, final_customer_review_clauses, when_clause_customer_review = \\\n",
    "    generate_task_vector_clauses(['customer', 'review'], 'customer_id', task_columns_dict, stype_dict)\n",
    "sql_query = f\"\"\"\n",
    "    SELECT\n",
    "        universal.timestamp as timestamp,\n",
    "        universal.customer_id as customer_id,\n",
    "    FROM\n",
    "        -- universal table\n",
    "        (\n",
    "            SELECT DISTINCT\n",
    "                t.timestamp,\n",
    "                r.customer_id\n",
    "            FROM\n",
    "                timestamp_df t\n",
    "                CROSS JOIN (\n",
    "                    SELECT \n",
    "                        customer_id,\n",
    "                        MIN(review_time) AS first_review\n",
    "                    FROM review\n",
    "                    GROUP BY customer_id\n",
    "                ) r\n",
    "            WHERE\n",
    "                -- Case 1: Reviews that fall within a window\n",
    "                EXISTS (\n",
    "                    SELECT 1\n",
    "                    FROM all_timestamp_df t2\n",
    "                    WHERE t2.timestamp <= t.timestamp\n",
    "                    AND r.first_review > t2.timestamp\n",
    "                    AND r.first_review <= t2.timestamp + INTERVAL '{timedelta}'\n",
    "                )\n",
    "                -- Case 2 (modified): If first review is before earliest timestamp, \n",
    "                -- include for ALL timestamps\n",
    "                OR (\n",
    "                    r.first_review <= (SELECT MIN(timestamp) FROM all_timestamp_df)\n",
    "                )\n",
    "        ) as universal\n",
    "\"\"\"\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register to duckdb\n",
    "split = 'train'\n",
    "db, train_timestamps = get_timestamps_for_split(dataset, stype_dict, split, timedelta, num_eval_timestamps)\n",
    "timestamp_df = pd.DataFrame({\"timestamp\": train_timestamps})\n",
    "all_timestamp_df = pd.DataFrame({\"timestamp\": train_timestamps})\n",
    "df_dict = {f\"{table_name}\": table.df for table_name, table in db.table_dict.items()}\n",
    "duckdb.register(\"timestamp_df\", timestamp_df)\n",
    "duckdb.register(\"all_timestamp_df\", all_timestamp_df)\n",
    "for table_name, df in df_dict.items():\n",
    "    duckdb.register(table_name, df)\n",
    "\n",
    "train_df = duckdb.sql(sql_query).df()\n",
    "assert (train_df['customer_id'].max() < len(db.table_dict['customer']))\n",
    "\n",
    "print(\"Number of customers: \", len(train_df['customer_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register to duckdb\n",
    "split = 'val'\n",
    "db, val_timestamps = get_timestamps_for_split(dataset, stype_dict, split, timedelta, num_eval_timestamps)\n",
    "timestamp_df = pd.DataFrame({\"timestamp\": val_timestamps})\n",
    "all_timestamp_df = pd.DataFrame({\"timestamp\": pd.concat([pd.Series(val_timestamps), pd.Series(train_timestamps)], ignore_index=True)})\n",
    "df_dict = {f\"{table_name}\": table.df for table_name, table in db.table_dict.items()}\n",
    "duckdb.register(\"timestamp_df\", timestamp_df)\n",
    "duckdb.register(\"all_timestamp_df\", all_timestamp_df)\n",
    "for table_name, df in df_dict.items():\n",
    "    duckdb.register(table_name, df)\n",
    "\n",
    "val_df = duckdb.sql(sql_query).df()\n",
    "assert (val_df['customer_id'].max() < len(db.table_dict['customer']))\n",
    "\n",
    "print(\"Number of customers: \", len(val_df['customer_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register to duckdb\n",
    "split = 'test'\n",
    "db, test_timestamps = get_timestamps_for_split(dataset, stype_dict, split, timedelta, num_eval_timestamps)\n",
    "timestamp_df = pd.DataFrame({\"timestamp\": test_timestamps})\n",
    "all_timestamp_df = pd.DataFrame({\"timestamp\": pd.concat([pd.Series(test_timestamps), pd.Series(val_timestamps), pd.Series(train_timestamps)], ignore_index=True)})\n",
    "df_dict = {f\"{table_name}\": table.df for table_name, table in db.table_dict.items()}\n",
    "duckdb.register(\"timestamp_df\", timestamp_df)\n",
    "duckdb.register(\"all_timestamp_df\", all_timestamp_df)\n",
    "for table_name, df in df_dict.items():\n",
    "    duckdb.register(table_name, df)\n",
    "\n",
    "test_df = duckdb.sql(sql_query).df()\n",
    "assert (test_df['customer_id'].max() < len(db.table_dict['customer']))\n",
    "\n",
    "print(\"Number of customers: \", len(test_df['customer_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_df.shape[1] == val_df.shape[1] == test_df.shape[1]\n",
    "entity_col = \"customer_id\"\n",
    "entity_table = \"customer\"\n",
    "time_col = \"timestamp\"\n",
    "\n",
    "# Create Table objects\n",
    "train_table = Table(df=train_df, fkey_col_to_pkey_table={entity_col: entity_table}, pkey_col=None, time_col=time_col)\n",
    "val_table = Table(df=val_df, fkey_col_to_pkey_table={entity_col: entity_table}, pkey_col=None, time_col=time_col)\n",
    "test_table = Table(df=test_df, fkey_col_to_pkey_table={entity_col: entity_table}, pkey_col=None, time_col=time_col)\n",
    "\n",
    "task_name = \"user-ssl\"\n",
    "path_dir = os.path.join(DATA_DIR, 'relbench', dataset_name, 'tasks', task_name)\n",
    "os.makedirs(path_dir, exist_ok=True)\n",
    "\n",
    "train_table.save(os.path.join(path_dir, 'train.parquet'))\n",
    "val_table.save(os.path.join(path_dir, 'val.parquet'))\n",
    "test_table.save(os.path.join(path_dir, 'test.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
