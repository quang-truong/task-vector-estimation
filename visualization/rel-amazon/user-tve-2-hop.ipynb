{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "rootutils.setup_root('.', indicator='.project-root', pythonpath=True)\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from relbench.base import Table\n",
    "from IPython.display import display\n",
    "import duckdb\n",
    "\n",
    "from src.helpers.task_vector_generation_helper import get_task_columns_dict, generate_task_vector_clauses, get_timestamps_for_split, transform_features\n",
    "from src.helpers.relbench_helper import get_dataset\n",
    "from src.helpers.dataset_helper import get_default_db\n",
    "from src.helpers.database_helper import read_stypes_cache\n",
    "from src.definitions import DATA_DIR\n",
    "\n",
    "dataset_name = 'rel-amazon'\n",
    "stype_dict = read_stypes_cache(os.path.join(DATA_DIR, dataset_name, 'stypes.json'))\n",
    "dataset = get_dataset(dataset_name)\n",
    "timedelta = pd.Timedelta(days=365 // 4)\n",
    "num_eval_timestamps = 1\n",
    "\n",
    "# Load unique categories\n",
    "with open('unique_categories.json', 'r') as f:\n",
    "    categories = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, _, _ = get_default_db(dataset_name, dataset, 'glove')\n",
    "task_columns_dict = get_task_columns_dict(db, stype_dict)\n",
    "\n",
    "sub_customer_review_clauses, final_customer_review_clauses, when_clause_customer_review = \\\n",
    "    generate_task_vector_clauses(['customer', 'review'], 'customer_id', task_columns_dict, stype_dict)\n",
    "sub_customer_review_product_clauses, final_customer_review_product_clauses, when_clause_customer_review_product = \\\n",
    "    generate_task_vector_clauses(['customer', 'review', 'product'], 'customer_id', task_columns_dict, stype_dict)\n",
    "sub_customer_review_review_0_clauses, final_customer_review_review_0_clauses, when_clause_customer_review_review_0 = \\\n",
    "    generate_task_vector_clauses(['customer', 'review', 'review'], 'customer_id', task_columns_dict, stype_dict, postfix=0)\n",
    "sub_customer_review_review_1_clauses, final_customer_review_review_1_clauses, when_clause_customer_review_review_1 = \\\n",
    "    generate_task_vector_clauses(['customer', 'review', 'review'], 'customer_id', task_columns_dict, stype_dict, postfix=1)\n",
    "sql_query = f\"\"\"\n",
    "    SELECT\n",
    "        universal.timestamp as timestamp,\n",
    "        universal.customer_id as customer_id,\n",
    "        \n",
    "        -- customer-review task\n",
    "        {final_customer_review_clauses},\n",
    "        \n",
    "        -- customer-review-product task\n",
    "        {final_customer_review_product_clauses},\n",
    "        \n",
    "        -- customer-review-review task\n",
    "        {final_customer_review_review_0_clauses},\n",
    "        {final_customer_review_review_1_clauses},\n",
    "        \n",
    "        -- The label column\n",
    "        CASE \n",
    "            WHEN \n",
    "                {when_clause_customer_review} OR \n",
    "                {when_clause_customer_review_product} OR \n",
    "                {when_clause_customer_review_review_0} OR \n",
    "                {when_clause_customer_review_review_1}\n",
    "            THEN 0 \n",
    "            ELSE 1 \n",
    "        END AS label\n",
    "    FROM\n",
    "        -- universal table\n",
    "        (\n",
    "            SELECT DISTINCT\n",
    "                t.timestamp,\n",
    "                r.customer_id\n",
    "            FROM\n",
    "                timestamp_df t\n",
    "                CROSS JOIN (\n",
    "                    SELECT \n",
    "                        customer_id,\n",
    "                        MIN(review_time) AS first_review\n",
    "                    FROM review\n",
    "                    GROUP BY customer_id\n",
    "                ) r\n",
    "            WHERE\n",
    "                -- Case 1: Reviews that fall within a window\n",
    "                EXISTS (\n",
    "                    SELECT 1\n",
    "                    FROM all_timestamp_df t2\n",
    "                    WHERE t2.timestamp <= t.timestamp\n",
    "                    AND r.first_review > t2.timestamp\n",
    "                    AND r.first_review <= t2.timestamp + INTERVAL '{timedelta}'\n",
    "                )\n",
    "                -- Case 2 (modified): If first review is before earliest timestamp, \n",
    "                -- include for ALL timestamps\n",
    "                OR (\n",
    "                    r.first_review <= (SELECT MIN(timestamp) FROM all_timestamp_df)\n",
    "                )\n",
    "        ) as universal\n",
    "        -- customer-review task\n",
    "            LEFT JOIN\n",
    "        (\n",
    "            SELECT\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id as customer__0__customer_id,\n",
    "                {sub_customer_review_clauses}\n",
    "            FROM\n",
    "                timestamp_df as t\n",
    "                LEFT JOIN (\n",
    "                    customer as customer__0\n",
    "                        INNER JOIN \n",
    "                    review as review__0 ON review__0.customer_id = customer__0.customer_id\n",
    "                )\n",
    "                ON\n",
    "                    review__0.review_time > t.timestamp AND\n",
    "                    review__0.review_time <= t.timestamp + INTERVAL '{timedelta}'\n",
    "            GROUP BY\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id\n",
    "        ) as customer_review_0\n",
    "            ON\n",
    "                universal.customer_id = customer_review_0.customer__0__customer_id\n",
    "                AND universal.timestamp = customer_review_0.timestamp\n",
    "        -- customer-review-product task\n",
    "            LEFT JOIN\n",
    "        (   \n",
    "            SELECT\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id as customer__0__customer_id,\n",
    "                {sub_customer_review_product_clauses}\n",
    "            FROM\n",
    "                timestamp_df as t\n",
    "                LEFT JOIN (\n",
    "                    customer as customer__0\n",
    "                        INNER JOIN \n",
    "                    review as review__0 ON review__0.customer_id = customer__0.customer_id\n",
    "                        INNER JOIN\n",
    "                    product as product__0 ON product__0.product_id = review__0.product_id\n",
    "                )\n",
    "                ON\n",
    "                    review__0.review_time > t.timestamp AND\n",
    "                    review__0.review_time <= t.timestamp + INTERVAL '{timedelta}'\n",
    "            GROUP BY\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id\n",
    "        ) as customer_review_product_0\n",
    "            ON \n",
    "                universal.customer_id = customer_review_product_0.customer__0__customer_id\n",
    "                AND universal.timestamp = customer_review_product_0.timestamp\n",
    "        -- customer-review-review task (JOIN on customer_id)\n",
    "            LEFT JOIN\n",
    "        (\n",
    "            SELECT\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id as customer__0__customer_id,\n",
    "                {sub_customer_review_review_0_clauses}\n",
    "            FROM\n",
    "                timestamp_df as t\n",
    "                LEFT JOIN (\n",
    "                    customer as customer__0\n",
    "                        INNER JOIN \n",
    "                    review as review__0 ON review__0.customer_id = customer__0.customer_id\n",
    "                        INNER JOIN\n",
    "                    review as review__1 ON review__1.customer_id = review__0.customer_id AND review__1.review_time <= review__0.review_time\n",
    "                )\n",
    "                ON\n",
    "                    review__0.review_time > t.timestamp AND\n",
    "                    review__0.review_time <= t.timestamp + INTERVAL '{timedelta}'\n",
    "            GROUP BY\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id\n",
    "        ) as customer_review_review_0\n",
    "            ON\n",
    "                universal.customer_id = customer_review_review_0.customer__0__customer_id\n",
    "                AND universal.timestamp = customer_review_review_0.timestamp\n",
    "        -- customer-review-review task (JOIN on product_id)\n",
    "            LEFT JOIN\n",
    "        (\n",
    "            SELECT\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id as customer__0__customer_id,\n",
    "                {sub_customer_review_review_1_clauses}\n",
    "            FROM\n",
    "                timestamp_df as t\n",
    "                LEFT JOIN (\n",
    "                    customer as customer__0\n",
    "                        INNER JOIN \n",
    "                    review as review__0 ON review__0.customer_id = customer__0.customer_id\n",
    "                        INNER JOIN\n",
    "                    review as review__1 ON review__1.product_id = review__0.product_id AND review__1.review_time <= review__0.review_time\n",
    "                )\n",
    "                ON\n",
    "                    review__0.review_time > t.timestamp AND\n",
    "                    review__0.review_time <= t.timestamp + INTERVAL '{timedelta}'\n",
    "            GROUP BY\n",
    "                t.timestamp,\n",
    "                customer__0.customer_id\n",
    "        ) as customer_review_review_1\n",
    "            ON\n",
    "                universal.customer_id = customer_review_review_1.customer__0__customer_id\n",
    "                AND universal.timestamp = customer_review_review_1.timestamp\n",
    "\"\"\"\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register to duckdb\n",
    "split = 'train'\n",
    "db, train_timestamps = get_timestamps_for_split(dataset, stype_dict, split, timedelta, num_eval_timestamps)\n",
    "timestamp_df = pd.DataFrame({\"timestamp\": train_timestamps})\n",
    "all_timestamp_df = pd.DataFrame({\"timestamp\": train_timestamps})\n",
    "df_dict = {f\"{table_name}\": table.df for table_name, table in db.table_dict.items()}\n",
    "duckdb.register(\"timestamp_df\", timestamp_df)\n",
    "duckdb.register(\"all_timestamp_df\", all_timestamp_df)\n",
    "for table_name, df in df_dict.items():\n",
    "    duckdb.register(table_name, df)\n",
    "\n",
    "new_df = duckdb.sql(sql_query).df()\n",
    "assert (new_df['customer_id'].max() < len(db.table_dict['customer']))\n",
    "\n",
    "# Transform training data\n",
    "label_0_rows = new_df[new_df['label'] == 0]\n",
    "label_1_rows = new_df[new_df['label'] == 1]\n",
    "\n",
    "print(label_0_rows.shape)\n",
    "print(label_1_rows.shape)\n",
    "print(f\"Label ratio: {len(label_0_rows) / (len(label_0_rows) + len(label_1_rows))} / {len(label_1_rows) / (len(label_0_rows) + len(label_1_rows))}\")\n",
    "\n",
    "# Transform training data\n",
    "scaled_train_df, std_scalers, onehot_encoder, _ = transform_features(label_0_rows, is_train=split == 'train')\n",
    "display(scaled_train_df.head(3))\n",
    "print(scaled_train_df.columns[2:])\n",
    "\n",
    "# Create a DataFrame with zeros for label_1_rows with same columns as scaled_train_df\n",
    "label_1_zeros = pd.DataFrame(0, index=label_1_rows.index, columns=scaled_train_df.columns[2:-1])\n",
    "\n",
    "# Add back timestamp, customer_id and label columns from label_1_rows\n",
    "label_1_zeros['timestamp'] = label_1_rows['timestamp']\n",
    "label_1_zeros['customer_id'] = label_1_rows['customer_id'] \n",
    "label_1_zeros['label'] = label_1_rows['label']\n",
    "\n",
    "# Concatenate with scaled_train_df\n",
    "scaled_train_df = pd.concat([scaled_train_df, label_1_zeros], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Number of customers: \", len(scaled_train_df['customer_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register to duckdb\n",
    "split = 'val'\n",
    "db, val_timestamps = get_timestamps_for_split(dataset, stype_dict, split, timedelta, num_eval_timestamps)\n",
    "timestamp_df = pd.DataFrame({\"timestamp\": val_timestamps})\n",
    "all_timestamp_df = pd.DataFrame({\"timestamp\": pd.concat([pd.Series(val_timestamps), pd.Series(train_timestamps)], ignore_index=True)})\n",
    "df_dict = {f\"{table_name}\": table.df for table_name, table in db.table_dict.items()}\n",
    "duckdb.register(\"timestamp_df\", timestamp_df)\n",
    "duckdb.register(\"all_timestamp_df\", all_timestamp_df)\n",
    "for table_name, df in df_dict.items():\n",
    "    duckdb.register(table_name, df)\n",
    "\n",
    "new_df = duckdb.sql(sql_query).df()\n",
    "assert (new_df['customer_id'].max() < len(db.table_dict['customer']))\n",
    "\n",
    "# Transform val data\n",
    "label_0_rows = new_df[new_df['label'] == 0]\n",
    "label_1_rows = new_df[new_df['label'] == 1]\n",
    "\n",
    "print(label_0_rows.shape)\n",
    "print(label_1_rows.shape)\n",
    "print(f\"Label ratio: {len(label_0_rows) / (len(label_0_rows) + len(label_1_rows))} / {len(label_1_rows) / (len(label_0_rows) + len(label_1_rows))}\")\n",
    "\n",
    "# Transform val data\n",
    "scaled_val_df, _, _, _ = transform_features(label_0_rows, std_scalers=std_scalers, onehot_encoder=onehot_encoder, is_train=split == 'train')\n",
    "display(scaled_val_df.head(3))\n",
    "\n",
    "# Create a DataFrame with zeros for label_1_rows with same columns as scaled_val_df\n",
    "label_1_zeros = pd.DataFrame(0, index=label_1_rows.index, columns=scaled_val_df.columns[2:-1])\n",
    "\n",
    "# Add back timestamp, customer_id and label columns from label_1_rows\n",
    "label_1_zeros['timestamp'] = label_1_rows['timestamp']\n",
    "label_1_zeros['customer_id'] = label_1_rows['customer_id'] \n",
    "label_1_zeros['label'] = label_1_rows['label']\n",
    "\n",
    "# Concatenate with scaled_val_df\n",
    "scaled_val_df = pd.concat([scaled_val_df, label_1_zeros], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Number of customers: \", len(scaled_val_df['customer_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register to duckdb\n",
    "split = 'test'\n",
    "db, test_timestamps = get_timestamps_for_split(dataset, stype_dict, split, timedelta, num_eval_timestamps)\n",
    "timestamp_df = pd.DataFrame({\"timestamp\": test_timestamps})\n",
    "all_timestamp_df = pd.DataFrame({\"timestamp\": pd.concat([pd.Series(test_timestamps), pd.Series(val_timestamps), pd.Series(train_timestamps)], ignore_index=True)})\n",
    "df_dict = {f\"{table_name}\": table.df for table_name, table in db.table_dict.items()}\n",
    "duckdb.register(\"timestamp_df\", timestamp_df)\n",
    "duckdb.register(\"all_timestamp_df\", all_timestamp_df)\n",
    "for table_name, df in df_dict.items():\n",
    "    duckdb.register(table_name, df)\n",
    "\n",
    "new_df = duckdb.sql(sql_query).df()\n",
    "assert (new_df['customer_id'].max() < len(db.table_dict['customer']))\n",
    "\n",
    "# Transform test data\n",
    "label_0_rows = new_df[new_df['label'] == 0]\n",
    "label_1_rows = new_df[new_df['label'] == 1]\n",
    "\n",
    "print(label_0_rows.shape)\n",
    "print(label_1_rows.shape)\n",
    "print(f\"Label ratio: {len(label_0_rows) / (len(label_0_rows) + len(label_1_rows))} / {len(label_1_rows) / (len(label_0_rows) + len(label_1_rows))}\")\n",
    "\n",
    "# Transform test data\n",
    "scaled_test_df, _, _, _ = transform_features(label_0_rows, std_scalers=std_scalers, onehot_encoder=onehot_encoder, is_train=split == 'train')\n",
    "display(scaled_test_df.head(3))\n",
    "\n",
    "# Create a DataFrame with zeros for label_1_rows with same columns as scaled_test_df\n",
    "label_1_zeros = pd.DataFrame(0, index=label_1_rows.index, columns=scaled_test_df.columns[2:-1])\n",
    "\n",
    "# Add back timestamp, customer_id and label columns from label_1_rows\n",
    "label_1_zeros['timestamp'] = label_1_rows['timestamp']\n",
    "label_1_zeros['customer_id'] = label_1_rows['customer_id'] \n",
    "label_1_zeros['label'] = label_1_rows['label']\n",
    "\n",
    "# Concatenate with scaled_test_df\n",
    "scaled_test_df = pd.concat([scaled_test_df, label_1_zeros], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Number of customers: \", len(scaled_test_df['customer_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scaled_train_df.shape[1] == scaled_val_df.shape[1] == scaled_test_df.shape[1]\n",
    "entity_col = \"customer_id\"\n",
    "entity_table = \"customer\"\n",
    "time_col = \"timestamp\"\n",
    "\n",
    "# Create Table objects\n",
    "train_table = Table(df=scaled_train_df, fkey_col_to_pkey_table={entity_col: entity_table}, pkey_col=None, time_col=time_col)\n",
    "val_table = Table(df=scaled_val_df, fkey_col_to_pkey_table={entity_col: entity_table}, pkey_col=None, time_col=time_col)\n",
    "test_table = Table(df=scaled_test_df, fkey_col_to_pkey_table={entity_col: entity_table}, pkey_col=None, time_col=time_col)\n",
    "\n",
    "task_name = \"user-tve-2-hop\"\n",
    "path_dir = os.path.join(DATA_DIR, 'relbench', dataset_name, 'tasks', task_name)\n",
    "os.makedirs(path_dir, exist_ok=True)\n",
    "\n",
    "train_table.save(os.path.join(path_dir, 'train.parquet'))\n",
    "val_table.save(os.path.join(path_dir, 'val.parquet'))\n",
    "test_table.save(os.path.join(path_dir, 'test.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
